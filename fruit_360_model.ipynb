{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP2Zxtr2gi5DdSN7COfcH3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PioDru/colab/blob/main/fruit_360_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eFxZWIS-84QE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix ,classification_report\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input , Dense ,Conv2D , MaxPooling2D , Flatten , Activation , Dropout ,Lambda\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Horea94/Fruit-Images-Dataset.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8tQmvh787l4",
        "outputId": "ea767abf-461f-490d-82da-035c11e8ecba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fruit-Images-Dataset'...\n",
            "remote: Enumerating objects: 385858, done.\u001b[K\n",
            "remote: Total 385858 (delta 0), reused 0 (delta 0), pack-reused 385858 (from 1)\u001b[K\n",
            "Receiving objects: 100% (385858/385858), 2.10 GiB | 16.10 MiB/s, done.\n",
            "Resolving deltas: 100% (1202/1202), done.\n",
            "Updating files: 100% (90503/90503), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "learning_rate = 0.1 # initial learning rate\n",
        "min_learning_rate = 0.00001 # once the learning rate reaches this value , do not decrease it further\n",
        "learning_rate_reduction_factor = 0.5 # the factor used when reducing the learning rate ->\n",
        "learning_rate *= learning_rate_reduction_factor\n",
        "patience = 3 # how many epochs to wait before reducing the learning rate when the loss plateaus\n",
        "verbose = 1 # controls the amount of logging done during training and testing: 0 - none , 1 - reports metrics after each batch , 2 - reports metrics after each epoch\n",
        "image_size = (100, 100) # width and height of the used images\n",
        "input_shape = (100, 100, 3) # the expected input shape for the trained models; since the images in the Fruit -360 are 100 x 100 RGB images , this is the required input shape\n",
        "\n",
        "use_label_file = False # set this to true if you want load the label names from a file; uses the label_file defined below; the file should contain the names of the used labels , each label on a separate line\n",
        "label_file = 'labels.txt'\n",
        "#base_dir = '../..' # relative path to the Fruit - Images - Dataset folder\n",
        "base_dir = '/content/Fruit-Images-Dataset' # relative path to the Fruit - Images - Dataset folder\n",
        "\n",
        "test_dir = os.path.join(base_dir , 'Test')\n",
        "train_dir = os.path.join(base_dir , 'Training')\n",
        "output_dir = 'output_files' # root folder in which to save the the output files; the files will be under output_files/model_name\n",
        "##############################################"
      ],
      "metadata": {
        "id": "cNjC-2oV9CGL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# if we want to train the network for a subset of the fruit classes instead of all, we can set the use_label_file to true and place in the label_file the classes we want to train for, one per line\n",
        "if use_label_file:\n",
        "    with open(label_file , \"r\") as f:\n",
        "        labels = [x.strip() for x in f.readlines()]\n",
        "else:\n",
        "    labels = os.listdir(train_dir)\n",
        "num_classes = len(labels)\n",
        "\n",
        "\n",
        "# create 2 charts , one for accuracy , one for loss , to show the evolution of these two metrics during the training process\n",
        "def plot_model_history(model_history , out_path=\"\"):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1, len(model_history.history['acc']) + 1), model_history.history['acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1, len(model_history.history['acc']) + 1), len(model_history.history['acc']))\n",
        "    axs[0].legend(['train'], loc='best')\n",
        "    # summarize history for loss\n",
        "\n",
        "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']))\n",
        "    axs[1].legend(['train'], loc='best')\n",
        "    # save the graph in a file called \"acc.png\" to be available for later; the model_name is provided when creating and training a model\n",
        "    if out_path:\n",
        "        plt.savefig(out_path + \"/acc.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# create a confusion matrix to visually represent incorrectly classified images\n",
        "def plot_confusion_matrix(y_true , y_pred , classes ,out_path=\"\"):\n",
        "    cm = confusion_matrix(y_true , y_pred)\n",
        "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
        "    plt.figure(figsize=(40, 40))\n",
        "    ax = sn.heatmap(df_cm , annot=True , square=True ,fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\":0.8})\n",
        "    if out_path:\n",
        "        plt.savefig(out_path + \"/confusion_matrix.png\") # as in the plot_model_history , the matrix is saved in a file called \"model_name_confusion_matrix.png\"\n",
        "    return ax\n",
        "\n",
        "\n",
        "# Randomly changes hue and saturation of the image to simulate variable lighting conditions\n",
        "\n",
        "def augment_image(x):\n",
        "    x = tf.image.random_saturation(x, 0.9, 1.2)\n",
        "    x = tf.image.random_hue(x, 0.02)\n",
        "    return x\n",
        "\n",
        "\n",
        "# given the train and test folder paths and a validation to test ratio , this method creates three generators\n",
        "# - the training generator uses (100 - validation_percent) of images from the train set\n",
        "# it applies random horizontal and vertical flips for data augmentation and generates batches randomly\n",
        "# - the validation generator uses the remaining validation_percent of images from the train set\n",
        "# does not generate random batches , as the model is not trained on this data\n",
        "# the accuracy and loss are monitored using the validation data so that the learning rate can be updated if the model hits a local optimum\n",
        "# - the test generator uses the test set without any form of augmentation\n",
        "# once the training process is done , the final values of accuracy and loss are calculated on this set\n",
        "def build_data_generators(train_folder , test_folder , labels=None , image_size=(100, 100), batch_size=50):\n",
        "    train_datagen = ImageDataGenerator(width_shift_range=0.0, height_shift_range=0.0, zoom_range=0.0, horizontal_flip=True ,vertical_flip=True , preprocessing_function=augment_image) # augmentation is done only on the train set (and optionally validation)\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_gen = train_datagen.flow_from_directory(train_folder , target_size=image_size ,class_mode='sparse', batch_size=batch_size ,shuffle=True , subset='training', classes=labels)\n",
        "    test_gen = test_datagen.flow_from_directory(test_folder , target_size=image_size , class_mode='sparse', batch_size=batch_size , shuffle=False , subset=None , classes=labels)\n",
        "    return train_gen , test_gen\n",
        "\n",
        "\n",
        "# Create a custom layer that converts the original image from # RGB to HSV and grayscale and concatenates the results\n",
        "# forming in input of size 100 x 100 x 4\n",
        "def convert_to_hsv_and_grayscale(x):\n",
        "    hsv = tf.image.rgb_to_hsv(x)\n",
        "    gray = tf.image.rgb_to_grayscale(x)\n",
        "    rez = tf.concat([hsv, gray], axis=-1)\n",
        "    return rez\n",
        "\n",
        "\n",
        "def network(input_shape , num_classes):\n",
        "    img_input = Input(shape=input_shape , name='data')\n",
        "    x = Lambda(convert_to_hsv_and_grayscale)(img_input)\n",
        "    x = Conv2D(16, (5, 5), strides=(1, 1), padding='same', name='conv1')(x)\n",
        "    x = Activation('relu', name='conv1_relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool1')(x)\n",
        "    x = Conv2D(32, (5, 5), strides=(1, 1), padding='same', name='conv2')(x)\n",
        "    x = Activation('relu', name='conv2_relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool2')(x)\n",
        "    x = Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv3')(x)\n",
        "    x = Activation('relu', name='conv3_relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool3')(x)\n",
        "    x = Conv2D(128, (5, 5), strides=(1, 1), padding='same', name='conv4')(x)\n",
        "    x = Activation('relu', name='conv4_relu')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool4')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='relu', name='fcl1')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(256, activation='relu', name='fcl2')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    out = Dense(num_classes , activation='softmax', name='predictions')(x)\n",
        "    rez = Model(inputs=img_input , outputs=out)\n",
        "    return rez\n",
        "\n",
        "# this method performs all the steps from data setup , training and testing the model and plotting the results\n",
        "# the model is any trainable model; the input shape and output number of classes is dependant on the dataset used , in this case the input is 100x100 RGB images and the output is a softmax layer with 118 probabilities\n",
        "# the name is used to save the classification report containing the f1 score of the model , the plots showing the loss and accuracy and the confusion matrix\n",
        "# the batch size is used to determine the number of images passed through the network at once , the number of steps per epochs is derived from this as (total number of images in set // batch size) + 1\n",
        "def train_and_evaluate_model(model , name=\"\", epochs=25, batch_size=50, verbose=verbose , useCkpt=False):\n",
        "    print(model.summary())\n",
        "    model_out_dir = os.path.join(output_dir , name)\n",
        "    if not os.path.exists(model_out_dir):\n",
        "        os.makedirs(model_out_dir)\n",
        "    if useCkpt:\n",
        "        #model.load_weights(model_out_dir + \"/model.h5\")\n",
        "        model.load_weights(model_out_dir + \"/model.keras\")\n",
        "\n",
        "    trainGen , testGen = build_data_generators(train_dir , test_dir , labels=labels , image_size=    image_size , batch_size=batch_size)\n",
        "    #optimizer = Adadelta(lr=learning_rate)\n",
        "    optimizer = Adadelta(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer , loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=patience , verbose=verbose ,factor=learning_rate_reduction_factor,min_lr=min_learning_rate)\n",
        "    #save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.h5\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "    save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.keras\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "\n",
        "    history = model.fit(trainGen , epochs=epochs , steps_per_epoch=(trainGen.n // batch_size) + 1,verbose=verbose , callbacks=[learning_rate_reduction , save_model])\n",
        "\n",
        "    #model.load_weights(model_out_dir + \"/model.h5\")\n",
        "    model.load_weights(model_out_dir + \"/model.keras\")\n",
        "\n",
        "    trainGen.reset()\n",
        "    loss_t , accuracy_t = model.evaluate(trainGen ,steps=(trainGen.n // batch_size) + 1, verbose=verbose)\n",
        "    loss , accuracy = model.evaluate(testGen , steps=(testGen.n // batch_size) + 1, verbose=verbose)\n",
        "    print(\"Train: accuracy = %f ; loss_v = %f\" % (\n",
        "    accuracy_t , loss_t))\n",
        "    print(\"Test: accuracy = %f ; loss_v = %f\" % (\n",
        "    accuracy , loss))\n",
        "    plot_model_history(history , out_path=model_out_dir)\n",
        "    testGen.reset()\n",
        "    y_pred = model.predict(testGen , steps=(testGen.n// batch_size) + 1, verbose=verbose)\n",
        "    y_true = testGen.classes[testGen.index_array]\n",
        "    plot_confusion_matrix(y_true , y_pred.argmax(axis=-1), labels , out_path=model_out_dir)\n",
        "    class_report = classification_report(y_true ,y_pred.argmax(axis=-1), target_names=labels)\n",
        "\n",
        "    with open(model_out_dir + \"/classification_report.txt\", \"w\") as text_file:\n",
        "        text_file.write(\"%s\" % class_report)\n",
        "\n",
        "\n",
        "print(labels)\n",
        "print(num_classes)\n",
        "model = network(input_shape=input_shape , num_classes=num_classes)\n",
        "train_and_evaluate_model(model , name=\"fruit-360 model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "idFKvE6x9Efp",
        "outputId": "ae0fd691-8105-4238-b58c-56638815a3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lemon Meyer', 'Peach 2', 'Tomato not Ripened', 'Apricot', 'Apple Red Delicious', 'Pitahaya Red', 'Dates', 'Mulberry', 'Tomato Maroon', 'Pear Stone', 'Cherry Rainier', 'Potato Sweet', 'Walnut', 'Blueberry', 'Corn', 'Orange', 'Corn Husk', 'Avocado', 'Lemon', 'Lychee', 'Nectarine Flat', 'Pear 2', 'Grape White 3', 'Kohlrabi', 'Apple Granny Smith', 'Pepper Red', 'Mango Red', 'Beetroot', 'Tomato 3', 'Mangostan', 'Tomato 4', 'Apple Pink Lady', 'Carambula', 'Mango', 'Cherry 1', 'Cauliflower', 'Banana Lady Finger', 'Apple Golden 3', 'Cantaloupe 2', 'Watermelon', 'Banana', 'Cherry Wax Black', 'Redcurrant', 'Chestnut', 'Onion Red', 'Plum 3', 'Plum', 'Pomegranate', 'Peach', 'Tomato Heart', 'Maracuja', 'Physalis with Husk', 'Fig', 'Apple Golden 2', 'Grape Blue', 'Hazelnut', 'Apple Red Yellow 1', 'Melon Piel de Sapo', 'Potato White', 'Apple Golden 1', 'Tomato Cherry Red', 'Cucumber Ripe 2', 'Apple Red 1', 'Apple Crimson Snow', 'Kaki', 'Pear Forelle', 'Physalis', 'Cherry Wax Yellow', 'Grapefruit Pink', 'Cherry Wax Red', 'Strawberry', 'Banana Red', 'Quince', 'Pepper Yellow', 'Cucumber Ripe', 'Rambutan', 'Apple Red Yellow 2', 'Cherry 2', 'Granadilla', 'Nut Forest', 'Cactus fruit', 'Guava', 'Cocos', 'Tamarillo', 'Kiwi', 'Pear Abate', 'Grape White 4', 'Tomato 1', 'Pear Kaiser', 'Pear Monster', 'Pear Red', 'Nectarine', 'Tomato 2', 'Pepino', 'Apple Braeburn', 'Cantaloupe 1', 'Huckleberry', 'Passion Fruit', 'Pepper Green', 'Salak', 'Nut Pecan', 'Apple Red 2', 'Tomato Yellow', 'Tangelo', 'Pepper Orange', 'Pear Williams', 'Avocado ripe', 'Onion White', 'Peach Flat', 'Clementine', 'Onion Red Peeled', 'Raspberry', 'Kumquats', 'Papaya', 'Pomelo Sweetie', 'Grape White 2', 'Potato Red Washed', 'Strawberry Wedge', 'Mandarine', 'Pear', 'Apple Red 3', 'Grapefruit White', 'Pineapple', 'Eggplant', 'Ginger Root', 'Limes', 'Grape Pink', 'Grape White', 'Potato Red', 'Pineapple Mini', 'Plum 2']\n",
            "131\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ data (\u001b[38;5;33mInputLayer\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │           \u001b[38;5;34m1,616\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_relu (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m12,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_relu (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m51,264\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_relu (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4 (\u001b[38;5;33mConv2D\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_relu (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ fcl1 (\u001b[38;5;33mDense\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m4,719,616\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ fcl2 (\u001b[38;5;33mDense\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m262,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ predictions (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)                 │          \u001b[38;5;34m33,667\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ data (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,616</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv3_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv4_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ pool4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ fcl1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ fcl2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,667</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,286,323\u001b[0m (20.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,286,323</span> (20.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,286,323\u001b[0m (20.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,286,323</span> (20.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Found 67692 images belonging to 131 classes.\n",
            "Found 22688 images belonging to 131 classes.\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1353/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - acc: 0.1041 - loss: 5.2189\n",
            "Epoch 1: loss improved from inf to 3.44024, saving model to output_files/fruit-360 model/model.keras\n",
            "\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 176ms/step - acc: 0.1044 - loss: 5.2163 - learning_rate: 0.0500\n",
            "Epoch 2/25\n",
            "\n",
            "Epoch 2: loss improved from 3.44024 to 0.00000, saving model to output_files/fruit-360 model/model.keras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step - acc: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0500\n",
            "Epoch 3/25\n",
            "\u001b[1m1353/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - acc: 0.6551 - loss: 1.2217\n",
            "Epoch 3: loss did not improve from 0.00000\n",
            "\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 165ms/step - acc: 0.6552 - loss: 1.2214 - learning_rate: 0.0500\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: loss did not improve from 0.00000\n",
            "\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11us/step - acc: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0500\n",
            "Epoch 5/25\n",
            "\u001b[1m1353/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - acc: 0.8389 - loss: 0.5294\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "\n",
            "Epoch 5: loss did not improve from 0.00000\n",
            "\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 165ms/step - acc: 0.8390 - loss: 0.5293 - learning_rate: 0.0500\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: loss did not improve from 0.00000\n",
            "\u001b[1m1354/1354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6us/step - acc: 0.0000e+00 - loss: 0.0000e+00 - learning_rate: 0.0250\n",
            "Epoch 7/25\n",
            "\u001b[1m 188/1354\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 164ms/step - acc: 0.9200 - loss: 0.2600"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O banana.jpg https://upload.wikimedia.org/wikipedia/commons/8/8a/Banana-Single.jpg"
      ],
      "metadata": {
        "id": "xjlbDGqdAY7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img4 = tf.keras.preprocessing.image.load_img('banana.jpg', target_size=(32, 32))\n",
        "img4 = tf.keras.preprocessing.image.img_to_array(img4)\n",
        "plt.imshow(img4.astype(np.int32))\n",
        "print(img4.shape)\n",
        "\n",
        "image4 = np.array([img4])\n",
        "\n",
        "labels[np.argmax(model.predict(image4))]\n",
        "print(labels[np.argmax(model.predict(image4))])"
      ],
      "metadata": {
        "id": "TtIw995FAaR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using picture from the dataset\n",
        "\n",
        "img2 = tf.keras.preprocessing.image.load_img('/content/Fruit-Images-Dataset/Test/Apple Red Delicious/0_100.jpg', target_size=(32, 32))\n",
        "img2 = tf.keras.preprocessing.image.img_to_array(img2)\n",
        "plt.imshow(img2.astype(np.int32))\n",
        "print(img2.shape)\n",
        "\n",
        "image2 = np.array([img2])\n",
        "\n",
        "labels[np.argmax(model.predict(image2))]\n",
        "print(labels[np.argmax(model.predict(image2))])"
      ],
      "metadata": {
        "id": "mPn1H6dhAjp6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}