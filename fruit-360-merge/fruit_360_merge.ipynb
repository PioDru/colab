{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nfQ4jD0QmZQ"
      },
      "source": [
        "# początek tworzenia systemu poniżej\n",
        "macie tutaj kod który utworzy wam zestaw danych do treningu\n",
        "\n",
        "prawa autorskie do kodu (ze świetnym opisem) są Piotra Markiewicza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69fjhYfUBR52"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqMW_70CYx2T"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix ,classification_report\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input , Dense ,Conv2D , MaxPooling2D , Flatten , Activation , Dropout ,Lambda\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import keras\n",
        "from keras import ops\n",
        "from PIL import Image, ImageOps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xky1zf-JbiJm"
      },
      "source": [
        "# getting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0djU_PgY-UZ"
      },
      "source": [
        "!git clone https://github.com/Horea94/Fruit-Images-Dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ-5El8UAeoV"
      },
      "source": [
        "# setting variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r80KrL-Kb9cx"
      },
      "source": [
        "# Parametry globalne\n",
        "\n",
        "##############################################\n",
        "learning_rate = 0.1 # initial learning rate\n",
        "min_learning_rate = 0.00001 # once the learning rate reaches this value , do not decrease it further\n",
        "learning_rate_reduction_factor = 0.5 # the factor used when reducing the learning rate ->\n",
        "learning_rate *= learning_rate_reduction_factor\n",
        "patience = 3 # how many epochs to wait before reducing the learning rate when the loss plateaus\n",
        "verbose = 1 # controls the amount of logging done during training and testing: 0 - none , 1 - reports metrics after each batch , 2 - reports metrics after each epoch\n",
        "image_size = (100, 100) # width and height of the used images\n",
        "input_shape = (100, 100, 3) # the expected input shape for the trained models; since the images in the Fruit -360 are 100 x 100 RGB images , this is the required input shape\n",
        "\n",
        "use_label_file = False # set this to true if you want load the label names from a file; uses the label_file defined below; the file should contain the names of the used labels , each label on a separate line\n",
        "label_file = 'labels.txt'\n",
        "#base_dir = '../..' # relative path to the Fruit - Images - Dataset folder\n",
        "base_dir = '/content/Fruit-Images-Dataset' # relative path to the Fruit - Images - Dataset folder\n",
        "\n",
        "test_dir = os.path.join(base_dir , 'Test')\n",
        "train_dir = os.path.join(base_dir , 'Training')\n",
        "output_dir = 'output_files' # root folder in which to save the the output files; the files will be under output_files/model_name\n",
        "##############################################\n",
        "image_size = image_size    # Wielkość wczytywanego zdjęcia = 100 x 100 pilkseli\n",
        "main_folder = base_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfjHlyNMAid8"
      },
      "source": [
        "# loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRm9-ncpdKsc"
      },
      "source": [
        "# Dane do szkolen (zdjęcia warzyw i owoców) przechowywane są odpowiednio w katalogu 'Training' i 'Test', które\n",
        "# mają tą samą strukturę pokazaną poniżej. Dla każdego gatunku owoca lub warzywa stworzony jest podkatalog,\n",
        "# którego nazwa będzie używana jako etykieta.\n",
        "\n",
        "# Training/Test\n",
        "# |________ Etykieta 1\n",
        "# |                  |____ Zdjecie 1\n",
        "# |                  |____ Zdjecie 2\n",
        "# |                  |____ ...\n",
        "# |                  |____ Zdjecie X\n",
        "# |________ Etykieta 2\n",
        "# |                  |____ Zdjecie 1\n",
        "# |                  |____ Zdjecie 2\n",
        "# |                  |____ ...\n",
        "# |                  |____ Zdjecie N\n",
        "# ...\n",
        "# |________ Etykieta M\n",
        "# |                  |____ Zdjecie 1\n",
        "# |                  |____ Zdjecie 2\n",
        "# |                  |____ ...\n",
        "# |                  |____ Zdjecie N\n",
        "\n",
        "\n",
        "# Tworzenie ścieżek do katalogów 'Training' i 'Test'\n",
        "train_image_folder = os.path.join(main_folder, 'Training')\n",
        "test_image_folder = os.path.join(main_folder, 'Test')\n",
        "\n",
        "labels = os.listdir(train_image_folder)\n",
        "\n",
        "train_data_generator = ImageDataGenerator()\n",
        "test_data_generator = ImageDataGenerator()\n",
        "\n",
        "# Metoda Flow_from_directory klasy ImageDataGenerator umożliwia import zdjęć zapisanych w odpowiedniej strukturze\n",
        "# folderów (zobacz przykład struktury przedstawionej powyżej)\n",
        "'''\n",
        "train_set = train_data_generator.flow_from_directory(\n",
        "    train_image_folder,           # Ścieżka do katalogu ze zdjęciami\n",
        "    target_size = image_size,     # Wielkość wczytywanego zdjęcia\n",
        "    #class_mode = 'categorical',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "    class_mode = 'sparse',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "    shuffle = True,               # True - zdjęcia będą losowo mieszane w całym zbiorze\n",
        "    classes = labels)             # Przypisanie etykiet do zdjęć\n",
        "\n",
        "test_set = test_data_generator.flow_from_directory(\n",
        "\n",
        "    test_image_folder,            # Ścieżka do katalogu ze zdjęciami\n",
        "    target_size = image_size,     # Wielkość wczytywanego zdjęcia\n",
        "    #class_mode = 'categorical',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "    class_mode = 'sparse',        # 'sparse' - zgodny z modelem\n",
        "    classes = labels)             # Przypisanie etykiet do zdjęć\n",
        "'''\n",
        "\n",
        "train_set = train_data_generator.flow_from_directory(\n",
        "    train_image_folder,           # Ścieżka do katalogu ze zdjęciami\n",
        "    target_size = image_size,     # Wielkość wczytywanego zdjęcia\n",
        "    #class_mode = 'categorical',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "    class_mode = 'sparse',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "\t  batch_size = 50,\n",
        "    shuffle = True,               # True - zdjęcia będą losowo mieszane w całym zbiorze\n",
        "    classes = labels)             # Przypisanie etykiet do zdjęć\n",
        "\n",
        "test_set = test_data_generator.flow_from_directory(\n",
        "\n",
        "    test_image_folder,            # Ścieżka do katalogu ze zdjęciami\n",
        "    target_size = image_size,     # Wielkość wczytywanego zdjęcia\n",
        "    #class_mode = 'categorical',   # 'binary' jeżeli mamy tylko dwie etykiety, 'categorical' jeżeli jest wiele etykiet\n",
        "    class_mode = 'sparse',        # 'sparse' - zgodny z modelem\n",
        "\t  batch_size = 50,\n",
        "\t  shuffle=False,\n",
        "    classes = labels)             # Przypisanie etykiet do zdjęć"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHv0lVK92cT"
      },
      "source": [
        "labels[15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHSra09gAvYw"
      },
      "source": [
        "# creating/training a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Db6I3qeGV9"
      },
      "source": [
        "keras.saving.get_custom_objects().clear()\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# if we want to train the network for a subset of the fruit classes instead of all, we can set the use_label_file to true and place in the label_file the classes we want to train for, one per line\n",
        "if use_label_file:\n",
        "    with open(label_file , \"r\") as f:\n",
        "        labels = [x.strip() for x in f.readlines()]\n",
        "else:\n",
        "    labels = os.listdir(train_dir)\n",
        "num_classes = len(labels)\n",
        "\n",
        "\n",
        "# create 2 charts , one for accuracy , one for loss , to show the evolution of these two metrics during the training process\n",
        "def plot_model_history(model_history , out_path=\"\"):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1, len(model_history.history['acc']) + 1), model_history.history['acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    #axs[0].set_xticks(np.arange(1, len(model_history.history['acc']) + 1), len(model_history.history['acc']))\n",
        "    #axs[0].set_xticks(np.arange(1, len(model_history.history['acc']) + 1), len(model_history.history['acc']))\n",
        "    axs[0].legend(['train'], loc='best')\n",
        "    # summarize history for loss\n",
        "\n",
        "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    #axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']))\n",
        "    #axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), len(model_history.history['loss']))\n",
        "    axs[1].legend(['train'], loc='best')\n",
        "    # save the graph in a file called \"acc.png\" to be available for later; the model_name is provided when creating and training a model\n",
        "    if out_path:\n",
        "        plt.savefig(out_path + \"/acc.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# create a confusion matrix to visually represent incorrectly classified images\n",
        "def plot_confusion_matrix(y_true , y_pred , classes ,out_path=\"\"):\n",
        "    cm = confusion_matrix(y_true , y_pred)\n",
        "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
        "    plt.figure(figsize=(40, 40))\n",
        "    ax = sn.heatmap(df_cm , annot=True , square=True ,fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\":0.8})\n",
        "    if out_path:\n",
        "        plt.savefig(out_path + \"/confusion_matrix.png\") # as in the plot_model_history , the matrix is saved in a file called \"model_name_confusion_matrix.png\"\n",
        "    return ax\n",
        "\n",
        "\n",
        "# Randomly changes hue and saturation of the image to simulate variable lighting conditions\n",
        "\n",
        "def augment_image(x):\n",
        "    x = tf.image.random_saturation(x, 0.9, 1.2)\n",
        "    x = tf.image.random_hue(x, 0.02)\n",
        "    return x\n",
        "\n",
        "\n",
        "# given the train and test folder paths and a validation to test ratio , this method creates three generators\n",
        "# - the training generator uses (100 - validation_percent) of images from the train set\n",
        "# it applies random horizontal and vertical flips for data augmentation and generates batches randomly\n",
        "# - the validation generator uses the remaining validation_percent of images from the train set\n",
        "# does not generate random batches , as the model is not trained on this data\n",
        "# the accuracy and loss are monitored using the validation data so that the learning rate can be updated if the model hits a local optimum\n",
        "# - the test generator uses the test set without any form of augmentation\n",
        "# once the training process is done , the final values of accuracy and loss are calculated on this set\n",
        "def build_data_generators(train_folder , test_folder , labels=None , image_size=(100, 100), batch_size=50):\n",
        "    train_datagen = ImageDataGenerator(width_shift_range=0.0, height_shift_range=0.0, zoom_range=0.0, horizontal_flip=True ,vertical_flip=True , preprocessing_function=augment_image) # augmentation is done only on the train set (and optionally validation)\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_gen = train_datagen.flow_from_directory(train_folder , target_size=image_size ,class_mode='sparse', batch_size=batch_size ,shuffle=True , subset='training', classes=labels)\n",
        "    test_gen = test_datagen.flow_from_directory(test_folder , target_size=image_size , class_mode='sparse', batch_size=batch_size , shuffle=False , subset=None , classes=labels)\n",
        "    return train_gen , test_gen\n",
        "\n",
        "\n",
        "# Create a custom layer that converts the original image from # RGB to HSV and grayscale and concatenates the results\n",
        "# forming in input of size 100 x 100 x 4\n",
        "@keras.saving.register_keras_serializable(package=\"my_package\", name=\"convert_to_hsv_and_grayscale\")\n",
        "def convert_to_hsv_and_grayscale(x):\n",
        "    hsv = tf.image.rgb_to_hsv(x)\n",
        "    gray = tf.image.rgb_to_grayscale(x)\n",
        "    rez = tf.concat([hsv, gray], axis=-1)\n",
        "    return rez"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this method performs all the steps from data setup , training and testing the model and plotting the results\n",
        "# the model is any trainable model; the input shape and output number of classes is dependant on the dataset used , in this case the input is 100x100 RGB images and the output is a softmax layer with 118 probabilities\n",
        "# the name is used to save the classification report containing the f1 score of the model , the plots showing the loss and accuracy and the confusion matrix\n",
        "# the batch size is used to determine the number of images passed through the network at once , the number of steps per epochs is derived from this as (total number of images in set // batch size) + 1\n",
        "def train_and_evaluate_model(model , name=\"\", epochs=25, batch_size=50, verbose=verbose , useCkpt=False):\n",
        "    print(model.summary())\n",
        "    model_out_dir = os.path.join(output_dir , name)\n",
        "    if not os.path.exists(model_out_dir):\n",
        "        os.makedirs(model_out_dir)\n",
        "    if useCkpt:\n",
        "        #model.load_weights(model_out_dir + \"/model.h5\")\n",
        "        model.load_weights(model_out_dir + \"/model.keras\")\n",
        "\n",
        "    trainGen , testGen = build_data_generators(train_dir , test_dir , labels=labels , image_size=image_size , batch_size=batch_size)\n",
        "    #optimizer = Adadelta(lr=learning_rate)\n",
        "    optimizer = Adadelta(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer , loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=patience , verbose=verbose ,factor=learning_rate_reduction_factor,min_lr=min_learning_rate)\n",
        "    #save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.h5\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "    save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.keras\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
        "        patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
        "        verbose=1,          # Verbosity mode (0: silent, 1: print messages)\n",
        "        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
        "    )\n",
        "    history = model.fit(trainGen , epochs=epochs , steps_per_epoch=(trainGen.n // batch_size) + 1,verbose=verbose , callbacks=[learning_rate_reduction , save_model])\n",
        "    #history = model.fit(trainGen , epochs=epochs , steps_per_epoch=(trainGen.n // batch_size) + 1,verbose=verbose , callbacks=[learning_rate_reduction , save_model, early_stopping])\n",
        "\n",
        "    #model.load_weights(model_out_dir + \"/model.h5\")\n",
        "    model.load_weights(model_out_dir + \"/model.keras\")\n",
        "    '''\n",
        "    trainGen.reset()\n",
        "    loss_t , accuracy_t = model.evaluate(trainGen ,steps=(trainGen.n // batch_size) + 1, verbose=verbose)\n",
        "    loss , accuracy = model.evaluate(testGen , steps=(testGen.n // batch_size) + 1, verbose=verbose)\n",
        "    print(\"Train: accuracy = %f ; loss_v = %f\" % (accuracy_t , loss_t))\n",
        "    print(\"Test: accuracy = %f ; loss_v = %f\" % (accuracy , loss))\n",
        "    plot_model_history(history , out_path=model_out_dir)\n",
        "    testGen.reset()\n",
        "    '''\n",
        "    y_pred = model.predict(testGen , steps=(testGen.n// batch_size) + 1, verbose=verbose)\n",
        "    '''\n",
        "    y_true = testGen.classes[testGen.index_array]\n",
        "    plot_confusion_matrix(y_true , y_pred.argmax(axis=-1), labels , out_path=model_out_dir)\n",
        "    class_report = classification_report(y_true ,y_pred.argmax(axis=-1), target_names=labels)\n",
        "\n",
        "    with open(model_out_dir + \"/classification_report.txt\", \"w\") as text_file:\n",
        "        text_file.write(\"%s\" % class_report)\n",
        "    '''"
      ],
      "metadata": {
        "id": "bdAnr6xBqbaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBuiEEc-dXiA"
      },
      "source": [
        "#model = tf.keras.models.Sequential()\n",
        "\n",
        "# tutaj musicie wstawić własny kod\n",
        "# .......\n",
        "model = tf.keras.Sequential([\n",
        "Input(shape=input_shape , name='data'),\n",
        "Lambda(convert_to_hsv_and_grayscale, output_shape=(100, 100, 4)),\n",
        "Conv2D(16, (5, 5), strides=(1, 1), padding='same', name='conv1'),\n",
        "Activation('relu', name='conv1_relu'),\n",
        "MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool1'),\n",
        "Conv2D(32, (5, 5), strides=(1, 1), padding='same', name='conv2'),\n",
        "Activation('relu', name='conv2_relu'),\n",
        "MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool2'),\n",
        "Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv3'),\n",
        "Activation('relu', name='conv3_relu'),\n",
        "MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool3'),\n",
        "Conv2D(128, (5, 5), strides=(1, 1), padding='same', name='conv4'),\n",
        "Activation('relu', name='conv4_relu'),\n",
        "MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool4'),\n",
        "Flatten(),\n",
        "Dense(1024, activation='relu', name='fcl1'),\n",
        "Dropout(0.2),\n",
        "Dense(256, activation='relu', name='fcl2'),\n",
        "Dropout(0.2),\n",
        "Dense(num_classes , activation='softmax', name='predictions')\n",
        "])\n",
        "\n",
        "#model.compile(# tutaj musicie wstawić własny kod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0fAzJimqfAx"
      },
      "source": [
        "#model.fit(# tutaj musicie wstawić własny kod)\n",
        "batch_size=50\n",
        "model_name = 'fruit-360_model'\n",
        "model_out_dir = os.path.join(output_dir , model_name)\n",
        "epochs=25\n",
        "#useCkpt=False\n",
        "useCkpt=True\n",
        "if not os.path.exists(model_out_dir):\n",
        "    os.makedirs(model_out_dir)\n",
        "if useCkpt:\n",
        "    #model.load_weights(model_out_dir + \"/model.h5\")\n",
        "    model.load_weights(model_out_dir + \"/model.keras\")\n",
        "trainGen , testGen = build_data_generators(train_dir , test_dir , labels=labels , image_size=image_size , batch_size=batch_size)\n",
        "#optimizer = Adadelta(lr=learning_rate)\n",
        "optimizer = Adadelta(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer , loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "model.summary()\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=patience , verbose=verbose ,factor=learning_rate_reduction_factor,min_lr=min_learning_rate)\n",
        "#save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.h5\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.keras\", monitor='loss',verbose=verbose ,save_best_only=True ,save_weights_only=False , mode='min',save_freq='epoch')\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
        "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,          # Verbosity mode (0: silent, 1: print messages)\n",
        "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "#history = model.fit(trainGen , epochs=epochs , steps_per_epoch=(trainGen.n // batch_size) + 1,verbose=verbose , callbacks=[learning_rate_reduction , save_model])\n",
        "history = model.fit(train_set , epochs=epochs , steps_per_epoch=(train_set.n // batch_size) + 1,verbose=verbose , callbacks=[learning_rate_reduction , save_model])\n",
        "model.load_weights(model_out_dir + \"/model.keras\")\n",
        "y_pred = model.predict(testGen , steps=(testGen.n// batch_size) + 1, verbose=verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4g3v_XUj4Jn"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrMvjVVA6Wm"
      },
      "source": [
        "# model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1OEcufGpeK1"
      },
      "source": [
        "#model.evaluate(# tutaj musicie wstawić własny kod)\n",
        "loss, accuracy = model.evaluate(test_set)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "print(labels)\n",
        "print(num_classes)\n",
        "model = network(input_shape=input_shape , num_classes=num_classes)\n",
        "#train_and_evaluate_model(model , name=\"fruit-360_model\")\n",
        "#train_and_evaluate_model(model , name=\"fruit-360_model\", useCkpt=True)\n",
        "train_and_evaluate_model(model , name=\"fruit-360_model\", epochs=10)\n",
        "'''"
      ],
      "metadata": {
        "id": "MAj4emBfqkDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUa8pveuBnLr"
      },
      "source": [
        "## model prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSm3TTxs19ec"
      },
      "source": [
        "!wget -O banana.jpg https://upload.wikimedia.org/wikipedia/commons/8/8a/Banana-Single.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrCb7J4q2Ug5"
      },
      "source": [
        "# preprocessing data (przygotowujemy zdjęcie z internetu do predykcji\n",
        "\n",
        "image = Image.open(\"banana.jpg\").convert(\"RGB\")\n",
        "image = image.resize((100, 100))\n",
        "\n",
        "image_np = np.array(image)\n",
        "\n",
        "img = np.array([image])\n",
        "#img = image_np.reshape(1, 100, 100, 3).astype('float32') / 255.0\n",
        "\n",
        "#plt.imshow(image/255)\n",
        "plt.imshow(image_np/255)\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxEO5W2kUB_V"
      },
      "source": [
        "#predykcja = # wasz kod tutaj\n",
        "predykcja = model.predict(img)\n",
        "\n",
        "predykcja\n",
        "print(predykcja)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aEsTcbtUWrF"
      },
      "source": [
        "# kod poniżej wyświetli nam nazwę rozpoznanej kategorii owocu\n",
        "print(np.argmax(predykcja))\n",
        "print(labels)\n",
        "#labels = os.listdir(train_image_folder)\n",
        "#labels[np.argmax(predykcja)]\n",
        "labels[np.argmax(predykcja)]\n",
        "print(labels[np.argmax(predykcja)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img4 = tf.keras.preprocessing.image.load_img('banana.jpg', target_size=(100, 100))\n",
        "img4 = tf.keras.preprocessing.image.img_to_array(img4)\n",
        "plt.imshow(img4.astype(np.int32))\n",
        "print(img4.shape)\n",
        "\n",
        "image4 = np.array([img4])\n",
        "\n",
        "labels[np.argmax(model.predict(image4))]\n",
        "print(labels[np.argmax(model.predict(image4))])"
      ],
      "metadata": {
        "id": "LFfI8E_xqpCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkWy4GC8Uho4"
      },
      "source": [
        "# predykcja używając zdjęcia z danych testowych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h7rNNAB8eqt"
      },
      "source": [
        "# prediction using picture from the dataset\n",
        "\n",
        "img2 = tf.keras.preprocessing.image.load_img('/content/Fruit-Images-Dataset/Test/Apple Red Delicious/0_100.jpg', target_size=(100, 100))\n",
        "img2 = tf.keras.preprocessing.image.img_to_array(img2)\n",
        "plt.imshow(img2.astype(np.int32))\n",
        "print(img2.shape)\n",
        "\n",
        "image2 = np.array([img2])\n",
        "\n",
        "labels[np.argmax(model.predict(image2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/output_files/fruit-360_model/model.keras\")"
      ],
      "metadata": {
        "id": "y-7vgFs6qwFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"/content/output_files/fruit-360_model/model.keras\")\n",
        "\n",
        "# Let's check:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(image4), reconstructed_model.predict(image4)\n",
        ")\n",
        "print(labels[np.argmax(model.predict(image4))])\n",
        "print(labels[np.argmax(reconstructed_model.predict(image4))])"
      ],
      "metadata": {
        "id": "p7ot3sldqwhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.save_weights(\"/content/output_files/fruit-360_model/model.weights.h5\")"
      ],
      "metadata": {
        "id": "txx_bEFaq0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# prompt: generate a csv file with labels from the labels variable\n",
        "\n",
        "import csv\n",
        "\n",
        "# Assuming 'labels' variable is defined as in the provided code\n",
        "# labels = os.listdir(train_image_folder)\n",
        "\n",
        "with open('labels.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['label'])  # Write header\n",
        "    for label in labels:\n",
        "        writer.writerow([label])\n"
      ],
      "metadata": {
        "id": "qy8jr7T4q027"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}